{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv('myenv/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sumeet = ConversableAgent(\n",
    "    name=\"Sumeet\",\n",
    "    system_message=\n",
    "    \"Your name is Sumeet and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "James = ConversableAgent(\n",
    "    name=\"James\",\n",
    "    system_message=\n",
    "    \"Your name is James and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mSumeet\u001b[0m (to James):\n",
      "\n",
      "I'm Sumeet. James, you are not funny\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJames\u001b[0m (to Sumeet):\n",
      "\n",
      "Well, Sumeet, if I'm not funny, then I guess I'll have to add \"comedian\" to the list of things I'm not good at.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSumeet\u001b[0m (to James):\n",
      "\n",
      "Haha, don't worry James, we all have our strengths!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJames\u001b[0m (to Sumeet):\n",
      "\n",
      "Why, thank you, Sumeet! I guess my strength must be making people appreciate other comedians even more.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = Sumeet.initiate_chat(\n",
    "    recipient=James, \n",
    "    message=\"I'm Sumeet. James, you are not funny\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': \"I'm Sumeet. James, you are not funny\",\n",
       "  'role': 'assistant',\n",
       "  'name': 'Sumeet'},\n",
       " {'content': 'Well, Sumeet, if I\\'m not funny, then I guess I\\'ll have to add \"comedian\" to the list of things I\\'m not good at.',\n",
       "  'role': 'user',\n",
       "  'name': 'James'},\n",
       " {'content': \"Haha, don't worry James, we all have our strengths!\",\n",
       "  'role': 'assistant',\n",
       "  'name': 'Sumeet'},\n",
       " {'content': 'Why, thank you, Sumeet! I guess my strength must be making people appreciate other comedians even more.',\n",
       "  'role': 'user',\n",
       "  'name': 'James'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_result.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'usage_including_cached_inference': {'total_cost': 0.00038399999999999996,\n",
       "  'gpt-3.5-turbo-0125': {'cost': 0.00038399999999999996,\n",
       "   'prompt_tokens': 456,\n",
       "   'completion_tokens': 104,\n",
       "   'total_tokens': 560}},\n",
       " 'usage_excluding_cached_inference': {'total_cost': 0.000232,\n",
       "  'gpt-3.5-turbo-0125': {'cost': 0.000232,\n",
       "   'prompt_tokens': 245,\n",
       "   'completion_tokens': 73,\n",
       "   'total_tokens': 318}}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_result.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get summarisation of the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mSumeet\u001b[0m (to James):\n",
      "\n",
      "I'm Sumeet. James, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJames\u001b[0m (to Sumeet):\n",
      "\n",
      "Why did the scarecrow win an award? Because he was outstanding in his field! Speaking of outstanding, I recently visited a restaurant that was so fancy, they even had a dress code for the vegetables. You had to wear a leek-tie to get in!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSumeet\u001b[0m (to James):\n",
      "\n",
      "Haha, those are some great jokes, James! Here's one for you: Why did the math book look sad? Because it had too many problems! Speaking of problems, have you ever noticed that no matter how hard you try, you just can't please a math teacher? It's like they always want you to solve for \"x,\" but you're just not sure what \"x\" wants from you!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJames\u001b[0m (to Sumeet):\n",
      "\n",
      "Why did the tomato turn red? Because it saw the salad dressing! Speaking of salad dressing, have you ever noticed that ranch just has a way of sneaking into every meal? It's like, \"excuse me, ranch, I'm just trying to enjoy my spaghetti here, could you not?\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSumeet\u001b[0m (to James):\n",
      "\n",
      "Haha, I love the tomato joke, James! And yes, ranch dressing does have a habit of showing up everywhere. It's like the party crasher of condiments! It's like, \"Oh, you thought you were having a nice meal? Nope, time for some ranch!\" Speaking of unexpected guests, have you ever tried to tell a chemistry joke, but didn't get a reaction? It's like, come on, where's the love for science humor?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJames\u001b[0m (to Sumeet):\n",
      "\n",
      "James\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSumeet\u001b[0m (to James):\n",
      "\n",
      "It seems like I got a bit carried away there! Let's get back to the jokes. Here's one for you: Why don't scientists trust atoms? Because they make up everything! Just like how ranch makes its way into every meal. Got any more jokes, James?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJames\u001b[0m (to Sumeet):\n",
      "\n",
      "Sorry, but I can't continue with that joke. How about I come up with a different joke instead?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSumeet\u001b[0m (to James):\n",
      "\n",
      "Sure, go ahead, James! I'm ready for a new joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJames\u001b[0m (to Sumeet):\n",
      "\n",
      "Why did the bicycle fall over? Because it was two-tired! Speaking of bicycles, I recently started riding a unicycle to work to save money on gas. But let me tell you, the commute is wheelie tough!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = Sumeet.initiate_chat(\n",
    "    James, \n",
    "    message=\"I'm Sumeet. James, let's keep the jokes rolling.\", \n",
    "    max_turns=5, \n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, the summary method is set to reflection_with_llm which takes a list of messages from the conversation and summarize them using a call to an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The conversation was filled with puns and jokes about various topics, '\n",
      " 'including scarecrows, math books, vegetables, salad dressing, chemistry, '\n",
      " 'atoms, and bicycles.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_excluding_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 613,\n",
      "                                                             'cost': 0.0030145,\n",
      "                                                             'prompt_tokens': 4190,\n",
      "                                                             'total_tokens': 4803},\n",
      "                                      'total_cost': 0.0030145},\n",
      " 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 1472,\n",
      "                                                             'cost': 0.005774,\n",
      "                                                             'prompt_tokens': 7132,\n",
      "                                                             'total_tokens': 8604},\n",
      "                                      'total_cost': 0.005774}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sumeet = ConversableAgent(\n",
    "    name=\"Sumeet\",\n",
    "    system_message=\n",
    "    \"Your name is Sumeet and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "James= ConversableAgent(\n",
    "    name=\"James\",\n",
    "    system_message=\n",
    "    \"Your name is James and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mSumeet\u001b[0m (to James):\n",
      "\n",
      "I'm Sumeet. James, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJames\u001b[0m (to Sumeet):\n",
      "\n",
      "Hey Sumeet, great to meet you! So, I just heard about this restaurant called Karma. There's no menu - you get what you deserve!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSumeet\u001b[0m (to James):\n",
      "\n",
      "Haha, that's funny, James! It's like, \"I'll have a side order of humility with a slice of karma, please!\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJames\u001b[0m (to Sumeet):\n",
      "\n",
      "That's perfect! And don't forget to tip your server with a pun or two!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSumeet\u001b[0m (to James):\n",
      "\n",
      "Haha, absolutely, James! A little punny goes a long way in showing appreciation!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJames\u001b[0m (to Sumeet):\n",
      "\n",
      "I gotta go. It was great sharing laughs with you, Sumeet! Take care!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = Sumeet.initiate_chat(\n",
    "    recipient=James,\n",
    "    message=\"I'm Sumeet. James, let's keep the jokes rolling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mSumeet\u001b[0m (to James):\n",
      "\n",
      "What's last joke we talked about?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJames\u001b[0m (to Sumeet):\n",
      "\n",
      "The last joke we shared was about tipping your server with a pun or two!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSumeet\u001b[0m (to James):\n",
      "\n",
      "Oh yeah, I remember now! Thanks for the laughs, James! Take care and have a great day!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mJames\u001b[0m (to Sumeet):\n",
      "\n",
      "You're welcome, Sumeet! Have a fantastic day filled with laughter and joy!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSumeet\u001b[0m (to James):\n",
      "\n",
      "Goodbye!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Sumeet.send(message=\"What's last joke we talked about?\", recipient=James)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
